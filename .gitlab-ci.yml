stages:
  - test
  - security
  - build
  - infra
  - deploy
  - notify

variables:
  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  POSTGRES_USER: 'django_educational_demo_application'
  POSTGRES_PASSWORD: ''
  POSTGRES_DB: 'test_django_educational_demo_application'
  POSTGRES_HOST_AUTH_METHOD: trust

.deploy_env_rules: &deploy_env_rules
  - if: '$CI_COMMIT_BRANCH == "main"'
    variables:
      DEPLOY_ENV: "prod"
  - if: '$CI_COMMIT_BRANCH =~ /^(dev|develop)$/'
    variables:
      DEPLOY_ENV: "dev"
  - when: never

.deploy_env_manual_rules: &deploy_env_manual_rules
  - if: '$CI_COMMIT_BRANCH == "main"'
    when: manual
    allow_failure: true
    variables:
      DEPLOY_ENV: "prod"
  - if: '$CI_COMMIT_BRANCH =~ /^(dev|develop)$/'
    when: manual
    allow_failure: true
    variables:
      DEPLOY_ENV: "dev"
  - when: never

.deploy_env_failure_rules: &deploy_env_failure_rules
  - if: '$CI_COMMIT_BRANCH == "main"'
    when: on_failure
    variables:
      DEPLOY_ENV: "prod"
  - if: '$CI_COMMIT_BRANCH =~ /^(dev|develop)$/'
    when: on_failure
    variables:
      DEPLOY_ENV: "dev"
  - when: never

# Run linters: pre-commit-hooks, django-upgrade, ruff, djLint
run_linters:
  stage: test
  image: ghcr.io/astral-sh/uv:python3.13-bookworm
  variables:
    UV_CACHE_DIR: $CI_PROJECT_DIR/.cache/uv
    PRE_COMMIT_HOME: $CI_PROJECT_DIR/.cache/pre-commit
  cache:
    key:
      files:
        - uv.lock
        - .pre-commit-config.yaml
    paths:
      - .cache/uv
      - .cache/pre-commit
  before_script:
    - apt-get update
    - apt-get install -y --no-install-recommends git
  script:
    - uv tool run pre-commit==4.5.1 run --show-diff-on-failure --color=always --all-files

# Run pytest
run_pytest:
  stage: test
  image: ghcr.io/astral-sh/uv:python3.13-bookworm
  services:
    - postgres:15
  variables:
    DATABASE_URL: pgsql://$POSTGRES_USER:$POSTGRES_PASSWORD@postgres/$POSTGRES_DB
  before_script:
    - apt-get update && apt-get install -y build-essential libpq-dev
    - uv sync --locked
  script:
    - uv run pytest
################################################################# TEST -> SECURITY #################################################################


# Check repo files for leaks of secrets
secret_scan:
  stage: security
  image: 
    name: zricethezav/gitleaks:latest
    entrypoint: [""]
  needs:
    - job: run_linters
    - job: run_pytest
  script:
    - gitleaks detect --source . --no-git --redact

# Dependancy scan
dependency_scan:
  stage: security
  image: ghcr.io/astral-sh/uv:python3.13-bookworm
  needs:
    - job: run_linters
    - job: run_pytest
  before_script:
    - uv sync --locked
    - uv pip install pip-audit
  script:
    - uv run pip-audit
  rules:
    - if: '$CI_COMMIT_BRANCH == "main"'
      allow_failure: false
    - when: on_success
      allow_failure: true

# Static application security testing (unsafe code contructions, possible sql injections, xss, unsifa file handling and unsafe django settings)
sast_semgrep:
  stage: security
  image: returntocorp/semgrep:latest
  needs:
    - job: run_linters
    - job: run_pytest
  script:
    - semgrep --config p/ci --error .

################################################################# SECURITY -> BUILD #################################################################


# Build with kaniko
build_image:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  needs:
    - job: run_linters
    - job: run_pytest
    - job: secret_scan
    - job: dependency_scan
    - job: sast_semgrep
  script:
    - mkdir -p /kaniko/.docker
    - |
      cat > /kaniko/.docker/config.json <<EOF
      {
        "auths": {
          "$CI_REGISTRY": {
            "username": "$CI_REGISTRY_USER",
            "password": "$CI_REGISTRY_PASSWORD"
          }
        }
      }
      EOF
    - >
      /kaniko/executor
      --context "$CI_PROJECT_DIR"
      --dockerfile "$CI_PROJECT_DIR/Dockerfile"
      --destination "$IMAGE_TAG"
      --cache=true

# Publish to GitLab Container Registry
publish_latest:
  stage: build
  image:
    name: gcr.io/go-containerregistry/crane:debug
    entrypoint: [""]
  needs:
    - job: build_image
  script:
    - crane auth login $CI_REGISTRY -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD
    - "printf '' > previous.env"
    - LATEST_ENV_TAG="$CI_REGISTRY_IMAGE:latest-${DEPLOY_ENV}"
    - PREVIOUS_ENV_TAG="$CI_REGISTRY_IMAGE:previous-${DEPLOY_ENV}"
    - |
      if crane digest "$LATEST_ENV_TAG" >/dev/null 2>&1; then
        crane tag "$LATEST_ENV_TAG" "previous-${DEPLOY_ENV}"
        echo "PREVIOUS_IMAGE=$PREVIOUS_ENV_TAG" >> previous.env
      else
        echo "PREVIOUS_IMAGE=" >> previous.env
      fi
    - crane tag "$IMAGE_TAG" "latest-${DEPLOY_ENV}"
    - echo "DEPLOY_ENV=${DEPLOY_ENV}" >> previous.env
  artifacts:
    reports:
      dotenv: previous.env
    paths:
      - previous.env
  rules: *deploy_env_rules


################################################################# BUILD -> INFRA #################################################################

# Create infra with terraform apply and prepare inventory from outputs
terraform_apply:
  stage: infra
  image:
    name: hashicorp/terraform:1.6
    entrypoint: [""]
  needs:
    - job: build_image
  variables:
    TF_VAR_cloud_id: "$CLOUD_ID"
    TF_VAR_folder_id: "$FOLDER_ID"
    TF_CLI_CONFIG_FILE: "$CI_PROJECT_DIR/infra/terraform.rc"
    AWS_DEFAULT_REGION: "ru-central1"
    AWS_EC2_METADATA_DISABLED: "true"
  before_script:
    - cd infra
    - |
      cat > "$TF_CLI_CONFIG_FILE" <<'EOF'
      provider_installation {
        network_mirror {
          url = "https://terraform-mirror.yandexcloud.net/"
          include = ["registry.terraform.io/*/*"]
        }
        direct {
          exclude = ["registry.terraform.io/*/*"]
        }
      }
      EOF
  script:
    - export TF_VAR_environment="${DEPLOY_ENV}"
    - |
      if [ -z "$YC_SERVICE_ACCOUNT_KEY" ]; then
        echo "YC_SERVICE_ACCOUNT_KEY is not set"
        exit 1
      fi
      if [ -f "$YC_SERVICE_ACCOUNT_KEY" ]; then
        export TF_VAR_service_account_key_file="$YC_SERVICE_ACCOUNT_KEY"
      else
        export TF_VAR_service_account_key_file="/tmp/yc-sa-key.json"
        first_char="$(printf '%s' "$YC_SERVICE_ACCOUNT_KEY" | head -c 1)"
        if [ "$first_char" = "{" ]; then
          printf '%s' "$YC_SERVICE_ACCOUNT_KEY" > "$TF_VAR_service_account_key_file"
        else
          printf '%s' "$YC_SERVICE_ACCOUNT_KEY" | base64 -d > "$TF_VAR_service_account_key_file"
        fi
        chmod 600 "$TF_VAR_service_account_key_file"
      fi
    - |
      if [ -z "$SSH_PUBLIC_KEY" ]; then
        echo "SSH_PUBLIC_KEY is not set"
        exit 1
      fi
      if printf '%s' "$SSH_PUBLIC_KEY" | grep -qE '^(ssh-|ecdsa-|sk-).* '; then
        export TF_VAR_ssh_public_key="$SSH_PUBLIC_KEY"
      else
        export TF_VAR_ssh_public_key="$(printf '%s' "$SSH_PUBLIC_KEY" | base64 -d)"
      fi
    - |
      if [ -z "${APP_DOMAIN:-}" ]; then
        echo "APP_DOMAIN is not set for DEPLOY_ENV=${DEPLOY_ENV}."
        echo "Set APP_DOMAIN as an environment-scoped CI/CD variable in GitLab."
        exit 1
      fi
      if ! printf '%s' "$APP_DOMAIN" | grep -Eq '^([A-Za-z0-9-]+\.)+[A-Za-z]{2,63}\.?$|^([0-9]{1,3}\.){3}[0-9]{1,3}$'; then
        echo "APP_DOMAIN has invalid format: ${APP_DOMAIN}"
        echo "Expected FQDN (example: app.example.com) or IPv4."
        exit 1
      fi
      export TF_VAR_app_domain="$APP_DOMAIN"
      export TF_VAR_manage_dns="${MANAGE_DNS:-false}"
      export TF_VAR_dns_zone="${DNS_ZONE:-example.com}"
      export TF_VAR_dns_zone_resource_name="${DNS_ZONE_RESOURCE_NAME:-diploma-zone-${DEPLOY_ENV}}"
      echo "Terraform DNS config: app_domain=${TF_VAR_app_domain}, manage_dns=${TF_VAR_manage_dns}, dns_zone=${TF_VAR_dns_zone}"
    - export AWS_ACCESS_KEY_ID="${YC_STORAGE_ACCESS_KEY:-$AWS_ACCESS_KEY_ID}"
    - export AWS_SECRET_ACCESS_KEY="${YC_STORAGE_SECRET_KEY:-$AWS_SECRET_ACCESS_KEY}"
    - terraform init -backend-config="access_key=${AWS_ACCESS_KEY_ID}" -backend-config="secret_key=${AWS_SECRET_ACCESS_KEY}" -backend-config="key=${DEPLOY_ENV}/terraform.tfstate"
    - terraform validate
    - terraform plan -out=tfplan
    - terraform apply -auto-approve tfplan
    - terraform output -json > tf_outputs.json
    - APP_PUBLIC_IP="$(terraform output -raw app_public_ip)"
    - MONITORING_PUBLIC_IP="$(terraform output -raw monitoring_public_ip)"
    - DB_PRIVATE_IP="$(terraform output -raw db_private_ip)"
    - APP_DOMAIN="$(terraform output -raw app_domain)"
    - APP_SUBNET_CIDR="$(terraform output -raw public_subnet_cidr)"
    - |
      cat > ../ansible/inventory/hosts.generated.ini <<EOF
      [app]
      app-vm ansible_host=${APP_PUBLIC_IP}

      [db]
      db-vm ansible_host=${DB_PRIVATE_IP} ansible_ssh_common_args='-o ProxyJump=ubuntu@${APP_PUBLIC_IP}'

      [monitoring]
      monitoring-vm ansible_host=${MONITORING_PUBLIC_IP}

      [all:vars]
      ansible_python_interpreter=/usr/bin/python3
      EOF
    - |
      cat > ../deploy.env <<EOF
      DEPLOY_ENV=${DEPLOY_ENV}
      APP_PUBLIC_IP=${APP_PUBLIC_IP}
      MONITORING_PUBLIC_IP=${MONITORING_PUBLIC_IP}
      DB_PRIVATE_IP=${DB_PRIVATE_IP}
      APP_DOMAIN=${APP_DOMAIN}
      APP_SUBNET_CIDR=${APP_SUBNET_CIDR}
      EOF
  artifacts:
    reports:
      dotenv: deploy.env
    paths:
      - infra/terraform.tfstate
      - infra/tf_outputs.json
      - ansible/inventory/hosts.generated.ini
      - deploy.env
  environment:
    name: $DEPLOY_ENV
  rules: *deploy_env_rules


# Manually destroy terraform resources when needed
terraform_destroy:
  stage: infra
  image:
    name: hashicorp/terraform:1.6
    entrypoint: [""]
  needs:
    - job: terraform_apply
  variables:
    TF_VAR_cloud_id: "$CLOUD_ID"
    TF_VAR_folder_id: "$FOLDER_ID"
    TF_CLI_CONFIG_FILE: "$CI_PROJECT_DIR/infra/terraform.rc"
    AWS_DEFAULT_REGION: "ru-central1"
    AWS_EC2_METADATA_DISABLED: "true"
  before_script:
    - cd infra
    - |
      cat > "$TF_CLI_CONFIG_FILE" <<'EOF'
      provider_installation {
        network_mirror {
          url = "https://terraform-mirror.yandexcloud.net/"
          include = ["registry.terraform.io/*/*"]
        }
        direct {
          exclude = ["registry.terraform.io/*/*"]
        }
      }
      EOF
  script:
    - export TF_VAR_environment="${DEPLOY_ENV}"
    - |
      if [ -z "$YC_SERVICE_ACCOUNT_KEY" ]; then
        echo "YC_SERVICE_ACCOUNT_KEY is not set"
        exit 1
      fi
      if [ -f "$YC_SERVICE_ACCOUNT_KEY" ]; then
        export TF_VAR_service_account_key_file="$YC_SERVICE_ACCOUNT_KEY"
      else
        export TF_VAR_service_account_key_file="/tmp/yc-sa-key.json"
        first_char="$(printf '%s' "$YC_SERVICE_ACCOUNT_KEY" | head -c 1)"
        if [ "$first_char" = "{" ]; then
          printf '%s' "$YC_SERVICE_ACCOUNT_KEY" > "$TF_VAR_service_account_key_file"
        else
          printf '%s' "$YC_SERVICE_ACCOUNT_KEY" | base64 -d > "$TF_VAR_service_account_key_file"
        fi
        chmod 600 "$TF_VAR_service_account_key_file"
      fi
    - |
      if [ -z "$SSH_PUBLIC_KEY" ]; then
        echo "SSH_PUBLIC_KEY is not set"
        exit 1
      fi
      if printf '%s' "$SSH_PUBLIC_KEY" | grep -qE '^(ssh-|ecdsa-|sk-).* '; then
        export TF_VAR_ssh_public_key="$SSH_PUBLIC_KEY"
      else
        export TF_VAR_ssh_public_key="$(printf '%s' "$SSH_PUBLIC_KEY" | base64 -d)"
      fi
    - |
      if [ -z "${APP_DOMAIN:-}" ]; then
        echo "APP_DOMAIN is not set for DEPLOY_ENV=${DEPLOY_ENV}."
        echo "Set APP_DOMAIN as an environment-scoped CI/CD variable in GitLab."
        exit 1
      fi
      if ! printf '%s' "$APP_DOMAIN" | grep -Eq '^([A-Za-z0-9-]+\.)+[A-Za-z]{2,63}\.?$|^([0-9]{1,3}\.){3}[0-9]{1,3}$'; then
        echo "APP_DOMAIN has invalid format: ${APP_DOMAIN}"
        echo "Expected FQDN (example: app.example.com) or IPv4."
        exit 1
      fi
      export TF_VAR_app_domain="$APP_DOMAIN"
      export TF_VAR_manage_dns="${MANAGE_DNS:-false}"
      export TF_VAR_dns_zone="${DNS_ZONE:-example.com}"
      export TF_VAR_dns_zone_resource_name="${DNS_ZONE_RESOURCE_NAME:-diploma-zone-${DEPLOY_ENV}}"
      echo "Terraform DNS config: app_domain=${TF_VAR_app_domain}, manage_dns=${TF_VAR_manage_dns}, dns_zone=${TF_VAR_dns_zone}"
    - export AWS_ACCESS_KEY_ID="${YC_STORAGE_ACCESS_KEY:-$AWS_ACCESS_KEY_ID}"
    - export AWS_SECRET_ACCESS_KEY="${YC_STORAGE_SECRET_KEY:-$AWS_SECRET_ACCESS_KEY}"
    - terraform init -backend-config="access_key=${AWS_ACCESS_KEY_ID}" -backend-config="secret_key=${AWS_SECRET_ACCESS_KEY}" -backend-config="key=${DEPLOY_ENV}/terraform.tfstate"
    - terraform destroy -auto-approve
  environment:
    name: $DEPLOY_ENV
  rules: *deploy_env_manual_rules

################################################################# INFRA -> DEPLOY #################################################################

# Deploy app, database and monitoring via Ansible
ansible_deploy:
  stage: deploy
  image: python:3.12-slim
  variables:
    ANSIBLE_CONFIG: ansible/ansible.cfg
    ANSIBLE_HOST_KEY_CHECKING: "False"
  needs:
    - job: terraform_apply
      artifacts: true
    - job: publish_latest
  before_script:
    - apt-get update
    - apt-get install -y openssh-client
    - pip install ansible
    - |
      if [ -z "$SSH_PRIVATE_KEY" ]; then
        echo "SSH_PRIVATE_KEY is not set"
        exit 1
      fi
      mkdir -p ~/.ssh
      chmod 700 ~/.ssh
      if [ -f "$SSH_PRIVATE_KEY" ]; then
        cp "$SSH_PRIVATE_KEY" ~/.ssh/id_rsa
      else
        if printf '%s' "$SSH_PRIVATE_KEY" | grep -q "BEGIN.*PRIVATE KEY"; then
          printf '%s' "$SSH_PRIVATE_KEY" | tr -d '\r' > ~/.ssh/id_rsa
        else
          printf '%s' "$SSH_PRIVATE_KEY" | base64 -d > ~/.ssh/id_rsa
        fi
      fi
      chmod 600 ~/.ssh/id_rsa
  script:
    - ansible-playbook -i ansible/inventory/hosts.generated.ini ansible/site.yml
        --extra-vars "image=$IMAGE_TAG
                      registry_url=$CI_REGISTRY
                      registry_user=$CI_REGISTRY_USER
                      registry_password=$CI_REGISTRY_PASSWORD
                      app_domain=$APP_DOMAIN
                      app_public_ip=$APP_PUBLIC_IP
                      db_host=$DB_PRIVATE_IP
                      db_name=${DB_NAME:-diploma}
                      db_user=${DB_USER:-diploma_user}
                      db_password=${DB_PASSWORD:-change-me-in-ci}
                      django_secret_key=${DJANGO_SECRET_KEY:-change-me-in-ci}
                      django_admin_url=${DJANGO_ADMIN_URL:-admin/}
                      caddy_acme_email=${TLS_ACME_EMAIL:-admin@$APP_DOMAIN}
                      app_subnet_cidr=${APP_SUBNET_CIDR:-10.10.1.0/24}"
  environment:
    name: $DEPLOY_ENV
  rules: *deploy_env_rules

# Perform health check of deployed app over HTTPS domain
health_check:
  stage: deploy
  image: curlimages/curl:latest
  needs:
    - job: terraform_apply
      artifacts: true
    - job: ansible_deploy
  script:
    - |
      echo "Running HTTPS health check for ${APP_DOMAIN}..."
      set +e
      curl -fsS --retry 30 --retry-delay 10 --retry-all-errors "https://${APP_DOMAIN}/health"
      https_health_rc=$?
      https_home_rc=0
      if [ "$https_health_rc" -eq 0 ]; then
        echo "Running HTTPS homepage check for ${APP_DOMAIN}..."
        curl -fsS --retry 30 --retry-delay 10 --retry-all-errors "https://${APP_DOMAIN}/"
        https_home_rc=$?
      else
        https_home_rc=$https_health_rc
      fi
      set -e

      if [ "$https_health_rc" -eq 0 ] && [ "$https_home_rc" -eq 0 ]; then
        echo "HTTPS checks passed for ${APP_DOMAIN}."
        exit 0
      fi

      if [ "$https_health_rc" -eq 6 ] || [ "$https_home_rc" -eq 6 ]; then
        echo "DNS resolution failed for ${APP_DOMAIN} (curl rc=6)."
        echo "Failing pipeline because the domain name is not resolvable."
        echo "Check APP_DOMAIN spelling and DNS A/AAAA records."
        exit 1
      fi

      if [ "${DEPLOY_ENV:-}" = "prod" ]; then
        echo "HTTPS checks failed in prod for ${APP_DOMAIN}."
        echo "health rc=${https_health_rc}, homepage rc=${https_home_rc}."
        echo "Most likely TLS certificate is not ready (for example ACME rate limit)."
        echo "Failing pipeline in prod to avoid false-green deploy status."
        exit 1
      fi

      echo "HTTPS checks are non-blocking only for non-prod deploy flow."
      echo "health rc=${https_health_rc}, homepage rc=${https_home_rc}."
      echo "Likely TLS is not ready yet (for example ACME rate limit) or DNS is not propagated."

      if [ -z "${APP_PUBLIC_IP:-}" ]; then
        echo "APP_PUBLIC_IP is empty, cannot run fallback HTTP checks"
        exit 1
      fi

      echo "Running fallback HTTP health check by IP ${APP_PUBLIC_IP}."
      curl -fsS --retry 30 --retry-delay 10 --retry-all-errors "http://${APP_PUBLIC_IP}/health"
      echo "Running fallback HTTP homepage check by IP ${APP_PUBLIC_IP}."
      curl -fsS --retry 30 --retry-delay 10 --retry-all-errors "http://${APP_PUBLIC_IP}/"
      echo "Fallback HTTP checks passed. Continuing pipeline despite HTTPS/TLS issues."
  environment:
    name: $DEPLOY_ENV
  rules: *deploy_env_rules

# Rollback to previous stable image from Container Registry
rollback:
  stage: deploy
  image: python:3.12-slim
  variables:
    ANSIBLE_CONFIG: ansible/ansible.cfg
    ANSIBLE_HOST_KEY_CHECKING: "False"
  needs:
    - job: health_check
    - job: terraform_apply
      artifacts: true
    - job: publish_latest
      artifacts: true
  before_script:
    - apt-get update
    - apt-get install -y openssh-client
    - pip install ansible
    - |
      if [ -z "$SSH_PRIVATE_KEY" ]; then
        echo "SSH_PRIVATE_KEY is not set"
        exit 1
      fi
      mkdir -p ~/.ssh
      chmod 700 ~/.ssh
      if [ -f "$SSH_PRIVATE_KEY" ]; then
        cp "$SSH_PRIVATE_KEY" ~/.ssh/id_rsa
      else
        if printf '%s' "$SSH_PRIVATE_KEY" | grep -q "BEGIN.*PRIVATE KEY"; then
          printf '%s' "$SSH_PRIVATE_KEY" | tr -d '\r' > ~/.ssh/id_rsa
        else
          printf '%s' "$SSH_PRIVATE_KEY" | base64 -d > ~/.ssh/id_rsa
        fi
      fi
      chmod 600 ~/.ssh/id_rsa
  script:
    - |
      if [ -z "$PREVIOUS_IMAGE" ]; then
        echo "PREVIOUS_IMAGE is not set, rollback skipped"
        exit 0
      fi
    - 'echo "Rollback to previous image: $PREVIOUS_IMAGE"'
    - ansible-playbook -i ansible/inventory/hosts.generated.ini ansible/site.yml
        --extra-vars "image=$PREVIOUS_IMAGE
                      registry_url=$CI_REGISTRY
                      registry_user=$CI_REGISTRY_USER
                      registry_password=$CI_REGISTRY_PASSWORD
                      app_domain=$APP_DOMAIN
                      app_public_ip=$APP_PUBLIC_IP
                      db_host=$DB_PRIVATE_IP
                      db_name=${DB_NAME:-diploma}
                      db_user=${DB_USER:-diploma_user}
                      db_password=${DB_PASSWORD:-change-me-in-ci}
                      django_secret_key=${DJANGO_SECRET_KEY:-change-me-in-ci}
                      django_admin_url=${DJANGO_ADMIN_URL:-admin/}
                      caddy_acme_email=${TLS_ACME_EMAIL:-admin@$APP_DOMAIN}
                      app_subnet_cidr=${APP_SUBNET_CIDR:-10.10.1.0/24}"
  environment:
    name: $DEPLOY_ENV
  rules: *deploy_env_failure_rules

################################################################# DEPLOY -> NOTIFY #################################################################

# Notify in Telegram after pipeline completion
notify_telegram_success:
  stage: notify
  image: curlimages/curl:latest
  allow_failure: true
  dependencies:
    - terraform_apply
  script:
    - |
      if [ -z "${TELEGRAM_BOT_TOKEN:-}" ] || [ -z "${TELEGRAM_CHAT_ID:-}" ]; then
        echo "TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID is not set, skipping notify stage."
        exit 0
      fi
    - |
      MONITORING_ENDPOINT="unknown"
      if [ -n "${MONITORING_PUBLIC_IP:-}" ]; then
        MONITORING_ENDPOINT="http://${MONITORING_PUBLIC_IP}:3000"
      fi
      MESSAGE="$(printf '%s\n' \
        '[DEPLOY][SUCCESS]' \
        "env: ${DEPLOY_ENV}" \
        "project: ${CI_PROJECT_PATH}" \
        "branch: ${CI_COMMIT_REF_NAME}" \
        "commit: ${CI_COMMIT_SHORT_SHA}" \
        "pipeline: ${CI_PIPELINE_URL}" \
        "${APP_DOMAIN:+app: https://${APP_DOMAIN}}" \
        "monitoring: ${MONITORING_ENDPOINT}")"
      curl -fsS -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
        --data-urlencode "chat_id=${TELEGRAM_CHAT_ID}" \
        --data-urlencode "text=${MESSAGE}" \
        --data-urlencode "disable_web_page_preview=true"
  rules: *deploy_env_rules

notify_telegram_failure:
  stage: notify
  image: curlimages/curl:latest
  allow_failure: true
  script:
    - |
      if [ -z "${TELEGRAM_BOT_TOKEN:-}" ] || [ -z "${TELEGRAM_CHAT_ID:-}" ]; then
        echo "TELEGRAM_BOT_TOKEN or TELEGRAM_CHAT_ID is not set, skipping notify stage."
        exit 0
      fi
    - |
      FAILED_JOB_NAME="unknown"
      if [ -n "${CI_API_V4_URL:-}" ] && [ -n "${CI_PROJECT_ID:-}" ] && [ -n "${CI_PIPELINE_ID:-}" ] && [ -n "${CI_JOB_TOKEN:-}" ]; then
        FAILED_JOBS_JSON="$(curl -fsS --header "JOB-TOKEN: ${CI_JOB_TOKEN}" \
          "${CI_API_V4_URL}/projects/${CI_PROJECT_ID}/pipelines/${CI_PIPELINE_ID}/jobs?scope[]=failed&order_by=id&sort=desc&per_page=20" || true)"
        if [ -n "${FAILED_JOBS_JSON}" ]; then
          FAILED_JOB_NAME="$(printf '%s' "${FAILED_JOBS_JSON}" \
            | grep -o '"name":"[^"]*"' \
            | head -n1 \
            | cut -d':' -f2- \
            | tr -d '"' || true)"
        fi
      fi
      if [ -z "${FAILED_JOB_NAME}" ]; then
        FAILED_JOB_NAME="unknown"
      fi
    - |
      MESSAGE="$(printf '%s\n' \
        '[DEPLOY][FAILED]' \
        "env: ${DEPLOY_ENV}" \
        "project: ${CI_PROJECT_PATH}" \
        "branch: ${CI_COMMIT_REF_NAME}" \
        "commit: ${CI_COMMIT_SHORT_SHA}" \
        "pipeline: ${CI_PIPELINE_URL}" \
        "failed_job: ${FAILED_JOB_NAME}")"
      curl -fsS -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
        --data-urlencode "chat_id=${TELEGRAM_CHAT_ID}" \
        --data-urlencode "text=${MESSAGE}" \
        --data-urlencode "disable_web_page_preview=true"
  rules: *deploy_env_failure_rules
